{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/larissacybyk/machine-learning/blob/main/jdj9ng_assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-RzEZEBR10z"
      },
      "source": [
        "# Assignment 1: Comparison of Regression Models on Predicting Medical Costs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qYDyMDTR100"
      },
      "source": [
        "### CS 4774 Machine Learning - Department of Computer Science - University of Virginia\n",
        "![Medical Cost](https://creditkarma-cms.imgix.net/wp-content/uploads/2018/04/boomers-gen-x-high-cost-medical-care.jpg)\n",
        "In this assignment, you will implement some learning models in the context of a **regression** problem in the [Medical Cost Personal Dataset on Kaggle](https://www.kaggle.com/mirichoi0218/insurance). Specifically, you will attempt to predict the medical cost billed by health insurance using other provided patient's data. For references, you may refer to [my slides](https://docs.google.com/presentation/d/10D1he89peAWaFgjtZlHpUzvOOAie_vIFT95htKCKgc0/edit#slide=id.p) or the Google Colab if you need additional sample codes to help with your assignment. To get started, you will need to upload/copy the dataset (.csv) into the same folder as this file.\n",
        "\n",
        "For deliverables, you must write code in Colab and submit the downloaded Jupyter Notebook file (.ipynb) to earn a total of 100 pts depending on how you perform in the following sections.\n",
        "\n",
        "To get started, you must make a copy of this template and rename it under this format: **yourUVaID_assignment_1.ipynb**. You will need to submit it with all of your outputs included to Gradecope.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0lLa-xiR101"
      },
      "source": [
        "***\n",
        "##  Task 1: SEE THE BIG PICTURE\n",
        "Write a paragraph explaining the context of the problem in which you are trying to investigate. We will assume that the data file is put into the same workspace on Colab. Then, you can write some code to load the CSV file and take a quick look at the dataset, and output the following:\n",
        "\n",
        " * How big is your dataset? (in terms of MB)\n",
        " * How many entries does it have?\n",
        " * How many features does it have?\n",
        " * Does it contain any categorical data?\n",
        " * Is there any missing value?\n",
        " * What are some basic statistics you can learn right away about this dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Context of the problem:\n",
        "The goal of this problem is to estimate the insurance charges based of a person's age, sex, bmi, etc. It will use the Medical Cost dataset from kaggle. A gradient descent model will be used to predict the charges for a person."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ujitZUYeR101"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1338 entries, 0 to 1337\n",
            "Data columns (total 7 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   age       1338 non-null   int64  \n",
            " 1   sex       1338 non-null   object \n",
            " 2   bmi       1338 non-null   float64\n",
            " 3   children  1338 non-null   int64  \n",
            " 4   smoker    1338 non-null   object \n",
            " 5   region    1338 non-null   object \n",
            " 6   charges   1338 non-null   float64\n",
            "dtypes: float64(2), int64(2), object(3)\n",
            "memory usage: 73.3+ KB\n",
            "None\n",
            "age         0\n",
            "sex         0\n",
            "bmi         0\n",
            "children    0\n",
            "smoker      0\n",
            "region      0\n",
            "charges     0\n",
            "dtype: int64\n",
            "               age          bmi     children       charges\n",
            "count  1338.000000  1338.000000  1338.000000   1338.000000\n",
            "mean     39.207025    30.663397     1.094918  13270.422265\n",
            "std      14.049960     6.098187     1.205493  12110.011237\n",
            "min      18.000000    15.960000     0.000000   1121.873900\n",
            "25%      27.000000    26.296250     0.000000   4740.287150\n",
            "50%      39.000000    30.400000     1.000000   9382.033000\n",
            "75%      51.000000    34.693750     2.000000  16639.912515\n",
            "max      64.000000    53.130000     5.000000  63770.428010\n"
          ]
        }
      ],
      "source": [
        "# Import some common packages\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# Your code goes here for this section, make sure you also include the output to answer the above questions.\n",
        "\n",
        "insurance = pd.read_csv(\"./insurance.csv\")\n",
        "\n",
        "# outputting answers\n",
        "print(insurance.info()) #73.3 kb --> 0.0733 MB, 1338 entries, 7 features, includes 3 categorical attributes (object type), \n",
        "print(insurance.isnull().sum()) # no null values\n",
        "print(insurance.describe()) # mean, min, max, median, first and third quartile, etc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xfw6nVzoR104"
      },
      "source": [
        "---\n",
        "##  Task 2: DATA DISCOVERY, CLEANING, AND SCALING\n",
        "\n",
        "**Data Discover:** Plot out all correlations among the features. You should notice some features are more correlated with your predicted value than other. This information will help you confirm that weights of your regression model later on.\n",
        "\n",
        "**Data Cleaning:** If your dataset has some missing values, make sure you are able to fill those values with the Imputer class. If your dataset has categorical features, make sure you conver those features into numerical using OneHotEncoder class.\n",
        "\n",
        "**Feature Scaling** More importantly, your task is to write some codes to normalize the value of each features as follow:\n",
        "\n",
        "* Subtract the mean value of each feature from the dataset\n",
        "* Scale (divide) the feature values by their respective standard deviation\n",
        "\n",
        "**Implementation Note:** You will need to integrate the above operations into a Pipeline to process and transform the training data, then use the same pipeline to transform any validation and testing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KI2IIJdHR104"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\l3n3c\\AppData\\Local\\Temp\\ipykernel_25200\\905539918.py:3: DeprecationWarning: \n",
            "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
            "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
            "but was not found to be installed on your system.\n",
            "If this would cause problems for you,\n",
            "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
            "        \n",
            "  from pandas.plotting import scatter_matrix # optional\n"
          ]
        },
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'Imputer' from 'sklearn.preprocessing' (c:\\Users\\l3n3c\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\__init__.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplotting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m scatter_matrix \u001b[38;5;66;03m# optional\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Imputer\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OneHotEncoder\n",
            "\u001b[1;31mImportError\u001b[0m: cannot import name 'Imputer' from 'sklearn.preprocessing' (c:\\Users\\l3n3c\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\__init__.py)"
          ]
        }
      ],
      "source": [
        "# You might want to use the following package\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pandas.plotting import scatter_matrix # optional\n",
        "from sklearn.preprocessing import Imputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Your code goes here for this section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 480x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#plotting correlation\n",
        "plt.matshow(insurance.corr(numeric_only=True))\n",
        "\n",
        "# plt.xticks(range(insurance.select_dtypes(['number']).shape[1]), insurance.select_dtypes(['number']).columns, fontsize=10, rotation=90)\n",
        "# plt.yticks(range(insurance.select_dtypes(['number']).shape[1]), insurance.select_dtypes(['number']).columns, fontsize=10)\n",
        "\n",
        "plt.xticks(range(insurance.select_dtypes(['number']).shape[1]), insurance.select_dtypes(['number']).columns, fontsize=10, rotation=90)\n",
        "plt.yticks(range(insurance.select_dtypes(['number']).shape[1]), insurance.select_dtypes(['number']).columns, fontsize=10)\n",
        "\n",
        "cb = plt.colorbar()\n",
        "cb.ax.tick_params(labelsize=5)\n",
        "\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# imports\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "\"['charges'] not found in axis\"",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[28], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m insurance_tr \u001b[38;5;241m=\u001b[39m insurance\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      2\u001b[0m insurance_tr\u001b[38;5;241m.\u001b[39mhead()\n\u001b[1;32m----> 3\u001b[0m insurance \u001b[38;5;241m=\u001b[39m \u001b[43minsurance_tr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcharges\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m insurance_labels \u001b[38;5;241m=\u001b[39m insurance_tr[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcharges\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      6\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(insurance, insurance_labels, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\l3n3c\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:5568\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5421\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5422\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5429\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5430\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5431\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5432\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5433\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5566\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5567\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5568\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5570\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5571\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5573\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5574\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5575\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5576\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\l3n3c\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:4782\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4780\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4781\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4782\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4785\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
            "File \u001b[1;32mc:\\Users\\l3n3c\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:4824\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4822\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4823\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4824\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4825\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4827\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4828\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\l3n3c\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:7069\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7068\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7069\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7070\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7071\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
            "\u001b[1;31mKeyError\u001b[0m: \"['charges'] not found in axis\""
          ]
        }
      ],
      "source": [
        "insurance_tr = insurance.copy()\n",
        "insurance_tr.head()\n",
        "insurance = insurance_tr.drop(\"charges\", axis=1)\n",
        "insurance_labels = insurance_tr[\"charges\"].copy()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(insurance, insurance_labels, test_size=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "imputer = SimpleImputer(strategy=\"median\")\n",
        "std_scaler = StandardScaler()\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "    (\"imputer\", imputer),\n",
        "    (\"std_scaler\", std_scaler)\n",
        "])\n",
        "num_col = insurance.select_dtypes(['number']).columns\n",
        "\n",
        "# converting categorical data\n",
        "cat_encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
        "cat_col = insurance.select_dtypes(['object']).columns\n",
        "\n",
        "# full pipeline\n",
        "full_pipeline = ColumnTransformer([\n",
        "    (\"num\", num_pipeline, num_col),\n",
        "    (\"cat\", cat_encoder, cat_col)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "insurance_prepared = full_pipeline.fit_transform(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRW5HPBzR106"
      },
      "source": [
        "- - -\n",
        "## Task 3. IMPLEMENT GRADIENT DESCENT\n",
        "The gradient descent formulation remain the same as one in the lecture. Keep in mind that you will need to add a column $\\textbf{x}_0$ with all 1s as part of the training data. You should write code to implement the **MyLinearRegression** class and its predefined methods.\n",
        "\n",
        "**Gradient Descent:** Notes that you may NOT call the library linear regression which defeats the purpose of this assignment. Make sure your code is well-vectorized."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mean_square_error(y_train, y_predicted):\n",
        "    cost = np.sum((y_train-y_predicted)**2) / len(y_train)\n",
        "    return cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "XOhAxyK1R107"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'y_train' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[27], line 76\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Your code goes here to call the instance of class MyLinearRegression\u001b[39;00m\n\u001b[0;32m     74\u001b[0m myGradientDescentModel \u001b[38;5;241m=\u001b[39m MyLinearRegression()\n\u001b[1;32m---> 76\u001b[0m myGradientDescentModel\u001b[38;5;241m.\u001b[39mfitUsingGradientDescent(X_train, \u001b[43my_train\u001b[49m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'y_train' is not defined"
          ]
        }
      ],
      "source": [
        "# NOTE: You may not use the library Linear Regression, but implement your own!\n",
        "# REMEMBER to place self.attribute = [] with value from your implementation\n",
        "\n",
        "class MyLinearRegression:\n",
        "  \"\"\"\n",
        "  Define what a linear regressor can do\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__ (self):\n",
        "    \"\"\"\n",
        "    Initialize the regressor\n",
        "    \"\"\"\n",
        "    self.theta = [] # parameter vector;\n",
        "    self.alpha = 0.001 # learning rate\n",
        "    self.cost  = -1 # cost function\n",
        "\n",
        "  def fitUsingGradientDescent(self, X_train, y_train):\n",
        "    \"\"\"\n",
        "    Train the regressor using gradient descent\n",
        "    \"\"\"\n",
        "    # implementation code here\n",
        "    self.theta = np.random.randn(X_train.shape[1],1)\n",
        "    self.theta, self.cost = self.gradientDescent(X_train, y_train, self.theta, self.alpha, 100)\n",
        "\n",
        "  def fitUsingNormalEquation(self, X_train, y_train):\n",
        "    \"\"\"\n",
        "    Training using the Normal (close form) equation\n",
        "    \"\"\"\n",
        "    # implementation code here for Task 4.\n",
        "    self.theta = []\n",
        "\n",
        "  def gradientDescent(self, X_train, y_train, theta, alpha, iters):\n",
        "    \"\"\"\n",
        "    Implementatation of the gradient descent\n",
        "    INPUT:\n",
        "    alpha: the learning rate\n",
        "    iters: number of iterations\n",
        "\n",
        "    OUTPUT:\n",
        "    theta: updated value for theta\n",
        "    cost: value of the cost function\n",
        "    \"\"\"\n",
        "    # implementation code here\n",
        "    cost = 0\n",
        "\n",
        "    for iteration in range(iters): \n",
        "      gradient = 2/len(X_train) * X_train.T.dot(X_train.dot(theta) - y_train)\n",
        "      theta = theta - alpha * gradient\n",
        "\n",
        "    y_predicted = self.predict(X_train)\n",
        "    cost = mean_square_error(y_train, y_predicted)\n",
        "\n",
        "    return theta, cost\n",
        "\n",
        "\n",
        "  def predict(self, X_test):\n",
        "    \"\"\"\n",
        "    Predicting the label\n",
        "    \"\"\"\n",
        "    # implementation code here\n",
        "    X = np.c_[np.ones((len(X_test), 1)), X_test]\n",
        "    y_predict = X.dot(self.theta)\n",
        "\n",
        "    return y_predict\n",
        "\n",
        "  def __str__(self):\n",
        "    \"\"\"\n",
        "    Print out the parameter out when call print()\n",
        "    \"\"\"\n",
        "    # implement here to return(\"Parameter vector is %f\" % self.theta)   }\n",
        "    return(\"Parameter vector is %f\".format(self.theta))\n",
        "\n",
        "# Your code goes here to call the instance of class MyLinearRegression\n",
        "myGradientDescentModel = MyLinearRegression()\n",
        "\n",
        "myGradientDescentModel.fitUsingGradientDescent(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mbKbih2R109"
      },
      "source": [
        "* **Learning Rate:** You will try out different learning rates for the dataset and find a learning rate that converges quickly. If you pick a learning rate, your plot of Cost Function $J(\\theta)$ against number of iteration will quickly decay to a small value. This also indicates that your implementation is correct. If your learning rate is too large, the cost function $J(\\theta)$ can diverge and blow up. From the below plot, you must be able to report the best learning rate the you found to earn credit for this section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBdljd94R109"
      },
      "outputs": [],
      "source": [
        "# Use the following code to plot out your learning rate\n",
        "# iters and cost must be supplied to plot out the cost function\n",
        "# You must plot multiple curves corresponding to different learning rates to justify the best one.\n",
        "#\n",
        "# plt.set_xlabel('Iterations')\n",
        "# plt.set_ylabel('Cost')\n",
        "# plt.set_title('Error vs. Training Iterations')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OSBr-iNR10_"
      },
      "source": [
        "- - -\n",
        "## Task 4. IMPLEMENT THE NORMAL EQUATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Pnn0NEhR10_"
      },
      "source": [
        "In my lecture, you learn that the closed form solution of linear regression using the normal equation formulation. Using the formula does not require any feature scaling, and should be straight forward to implement:\n",
        "\n",
        "$\n",
        "    \\mathbf{\\theta} = ({\\mathbf{X}^{T}\\mathbf{X}})^{-1}\\mathbf{X}^{T}\\mathbf{y}.\n",
        "$\n",
        "\n",
        "Note that you still need to add a column of 1's to the $\\mathbf{\n",
        "X}$ matrix to have an intercept term."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4t5jNtbR11B"
      },
      "outputs": [],
      "source": [
        "# Implement the normalEquation method of the MyLinearRegression Class before execute the code below:\n",
        "myNormalEquationModel = MyLinearRegression()\n",
        "myNormalEquationModel.fitUsingNormalEquation(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5el9T4eR11D"
      },
      "source": [
        "- - -\n",
        "## Task 5. COMPARE DIFFERENT IMPLEMENTATIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScvMKU-zR11D"
      },
      "source": [
        "You should be able to evaluate and compare your gradient descent as well as normal equation implementation of linear regression. In theory, they should be the same, or at least similar. For good measures, you must use the built-in library **Scholastic Gradient Descent (SGD)** as a third model for comparison. For each model, you must compute the RMSE on the **test set** as performance measure. The good news is that you can call library functions to compute these as shown below instead of writing your own code:\n",
        "\n",
        "* Which one yields the best performance measure for your dataset?\n",
        "* What is your assessment of the error? Good? Okay? Terrible?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtvlmtyCR11E"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Use the built-in SGD Regressor model\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "mySGDModel = SGDRegressor()\n",
        "#mySGDModel.fit(X_train,y_train)\n",
        "#y_predict = mySGDModel.predict(X_test)\n",
        "#mse = mean_squared_error(y_test, y_predict)\n",
        "#mySGDModel_rmse = np.sqrt(mse)\n",
        "# print(mySGDModel_rmse)\n",
        "\n",
        "# myGradientDescentModel_rmse\n",
        "# myNormalEquationModel_rmse\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmaBPxD_R11G"
      },
      "source": [
        "- - -\n",
        "## Task 6. PRESENT YOUR SOLUTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI7TNvZsR11H"
      },
      "source": [
        "Now that you need to write a short memo of one paragraph to be read by a non-technical audience (ie. your manager/boss). Focus on answering the following:\n",
        "\n",
        "* How can you pitch your solution to this project?\n",
        "* What did you learn so far about the problem?\n",
        "* Is there any insight moving forward to improve the solution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrv4waCfR11H"
      },
      "outputs": [],
      "source": [
        "# Your paragraph goes here for this section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1vTd45lR11J"
      },
      "source": [
        "- - -\n",
        "### NEED HELP?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ionUS2eLR11K"
      },
      "source": [
        "In case you get stuck in any step in the process, you may find some useful information from:\n",
        "\n",
        " * Consult my [slides](https://docs.google.com/presentation/d/10D1he89peAWaFgjtZlHpUzvOOAie_vIFT95htKCKgc0/edit?usp=sharing) and/or the textbook\n",
        " * Talk to the TA, they are available and there to help you during [office hour](http://bit.ly/cs4774oh)\n",
        " * Come talk to me or email me <nn4pj@virginia.edu> with subject starting \"CS 4774 Assignment 1:...\".\n",
        "\n",
        "Best of luck and have fun!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
